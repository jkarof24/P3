import random
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import pandas as pd
import seaborn as sns
import dig
import matplotlib.pyplot as plt
from torch_geometric.datasets import TUDataset
from torch_geometric.loader import DataLoader
from torch_geometric.nn import GCNConv, GATConv, SAGEConv, global_mean_pool
from torch_geometric.explain import Explainer, GNNExplainer, PGExplainer
from sklearn.metrics import roc_auc_score
from dig.xgraph.method.subgraphx import SubgraphX

# Set seed for reproducibility
SEED = 42
random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
torch.cuda.manual_seed_all(SEED) if torch.cuda.is_available() else None
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# GNN Model
class GNN_Model(nn.Module):
    def __init__(self, layer_type, in_channels, hidden_channels, out_channels):
        super().__init__()
        conv_map = {'GCN': GCNConv, 'GAT': GATConv, 'GraphSAGE': SAGEConv}
        Conv = conv_map.get(layer_type)
        if Conv is None:
            raise ValueError(f"Unknown layer_type: {layer_type}")
        self.conv1 = Conv(in_channels, hidden_channels)
        self.conv2 = Conv(hidden_channels, hidden_channels)
        self.conv3 = Conv(hidden_channels, hidden_channels)
        self.lin = nn.Linear(hidden_channels, out_channels)

    def forward(self, x, edge_index, batch=None):
        if batch is None:
            batch = torch.zeros(x.size(0), dtype=torch.long, device=x.device)
        x = F.relu(self.conv1(x, edge_index))
        x = F.relu(self.conv2(x, edge_index))
        x = F.relu(self.conv3(x, edge_index))
        x = global_mean_pool(x, batch)
        return self.lin(x)

# Utilities
def calculate_metrics(model, x, edge_index, batch, binary_mask, target_class):
    model.eval()
    with torch.no_grad():
        out = model(x, edge_index, batch)
        prob_orig = F.softmax(out, dim=1)[0, target_class].item()
        num_edges = edge_index.size(1)
        sparsity = 1.0 - (binary_mask.sum().item() / num_edges) if num_edges > 0 else 0.0
        
        # Fidelity+
        remove_mask = ~binary_mask
        edge_index_remove = edge_index[:, remove_mask]
        prob_remove = F.softmax(model(x, edge_index_remove, batch), dim=1)[0, target_class].item() if edge_index_remove.size(1) > 0 else 0.5
        fid_plus = prob_orig - prob_remove
        
        # Fidelity-
        edge_index_keep = edge_index[:, binary_mask]
        prob_keep = F.softmax(model(x, edge_index_keep, batch), dim=1)[0, target_class].item() if edge_index_keep.size(1) > 0 else 0.5
        fid_minus = prob_orig - prob_keep
    
    return fid_plus, fid_minus, sparsity

def normalize_edge_mask(edge_mask):
    if isinstance(edge_mask, torch.Tensor):
        return edge_mask.view(-1).float().to(DEVICE)
    raise ValueError("Unsupported edge_mask type")

def make_target(pred, device):
    return torch.tensor([int(pred)], device=device)

def subgraphx_to_edge_mask(data, subgraph_nodes):
    sub_nodes = torch.tensor(list(subgraph_nodes), device=DEVICE, dtype=torch.long)
    node_in = torch.zeros(data.x.size(0), dtype=torch.bool, device=DEVICE)
    node_in[sub_nodes] = True
    src, dst = data.edge_index
    return node_in[src] & node_in[dst]

# Training functions
def train_gnn(model, train_loader, val_loader, epochs=50):
    optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)
    best_auc = 0.0
    best_state = None
    for epoch in range(epochs):
        model.train()
        for batch in train_loader:
            batch = batch.to(DEVICE)
            optimizer.zero_grad()
            out = model(batch.x, batch.edge_index, batch.batch)
            loss = F.cross_entropy(out, batch.y)
            loss.backward()
            optimizer.step()
        
        model.eval()
        y_true, y_probs = [], []
        for batch in val_loader:
            batch = batch.to(DEVICE)
            out = model(batch.x, batch.edge_index, batch.batch)
            probs = F.softmax(out, dim=1)[:, 1] if out.shape[1] > 1 else torch.sigmoid(out).squeeze()
            y_probs.extend(probs.detach().cpu().numpy())
            y_true.extend(batch.y.detach().cpu().numpy())
        
        if len(set(y_true)) > 1:
            auc = roc_auc_score(y_true, y_probs)
            if auc > best_auc:
                best_auc = auc
                best_state = model.state_dict()
    
    if best_state:
        model.load_state_dict(best_state)
    return best_auc

def train_pg_explainer(explainer, loader, epochs=500):
    explainer.algorithm.to(DEVICE)
    for epoch in range(epochs):
        for batch in loader:
            batch = batch.to(DEVICE)
            with torch.no_grad():
                out = explainer.model(batch.x, batch.edge_index, batch.batch)
                target = out.argmax(dim=1).to(DEVICE)
            try:
                loss = explainer.algorithm.train(epoch, explainer.model, batch.x, batch.edge_index, target=target, batch=batch.batch)
            except TypeError:
                loss = explainer.algorithm.train(explainer.model, batch.x, batch.edge_index, target=target, batch=batch.batch)

# Experiment
def run_experiment(reg_strength=0.01, pct=0.10):
    dataset = TUDataset(root='data/TUDataset', name='MUTAG').shuffle()
    n = len(dataset)
    train_loader = DataLoader(dataset[:int(0.8*n)], batch_size=32, shuffle=True)
    val_loader = DataLoader(dataset[int(0.8*n):int(0.9*n)], batch_size=32)
    test_loader = DataLoader(dataset[int(0.9*n):], batch_size=1, shuffle=False)
    
    results = []
    for model_name in ['GCN', 'GAT', 'GraphSAGE']:
        print(f"\n=== {model_name} ===")
        model = GNN_Model(model_name, dataset.num_features, 64, dataset.num_classes).to(DEVICE)
        auc = train_gnn(model, train_loader, val_loader)
        print(f"Validation AUC: {auc:.4f}")
        
        # Explainers
        gnn_explainer = Explainer(
            model=model, algorithm=GNNExplainer(epochs=100),
            explanation_type='phenomenon', edge_mask_type='object',
            model_config=dict(mode='multiclass_classification', task_level='graph', return_type='probs')
        )
        gnn_explainer.algorithm.coeffs['edge_size'] = reg_strength
        
        pg_algo = PGExplainer(epochs=500, lr=0.003, size_loss_weight=reg_strength)
        pg_explainer = Explainer(
            model=model, algorithm=pg_algo,
            explanation_type='phenomenon', edge_mask_type='object',
            model_config=dict(mode='multiclass_classification', task_level='graph', return_type='probs')
        )
        train_pg_explainer(pg_explainer, train_loader, epochs=500)
        
        subgraphx_explainer = SubgraphX(
            model=model, num_classes=dataset.num_classes, device=DEVICE, explain_graph=True,
            reward_method='gnn_score', rollout=10, c_puct=10.0, min_atoms=3, expand_atoms=12
        )
        
        explainers = {'GNNExplainer': gnn_explainer, 'PGExplainer': pg_explainer, 'SubgraphX': subgraphx_explainer}
        
        for name, explainer in explainers.items():
            count = 0
            for i, data in enumerate(test_loader):
                data = data.to(DEVICE)
                with torch.no_grad():
                    out = model(data.x, data.edge_index, data.batch)
                    pred = out.argmax(dim=1).item()
                if pred != int(data.y.item()):
                    continue
                
                try:
                    if name == 'SubgraphX':
                        _, explanation_results, _ = explainer(data.x, data.edge_index, max_nodes=5)
                        sub_out = explanation_results[pred]  # Select results for the predicted class
                        sub_nodes = sub_out.get('coalition') if isinstance(sub_out, dict) else None
                        if sub_nodes is None and isinstance(sub_out, list):
                            best = max(sub_out, key=lambda d: d.get('reward', 0.0))
                            sub_nodes = best.get('coalition', [])
                        if sub_nodes is None:
                            raise RuntimeError("No subgraph found in SubgraphX output")
                        edge_mask_bool = subgraphx_to_edge_mask(data, sub_nodes)
                        em = edge_mask_bool.float()
                    else:
                        target = make_target(pred, DEVICE)
                        explanation = explainer(data.x, data.edge_index, batch=data.batch, target=target)
                        raw_mask = explanation.edge_mask or explanation.get('edge_mask')
                        if raw_mask is None:
                            raise RuntimeError("No edge_mask found")
                        em = normalize_edge_mask(raw_mask)
                    
                    # Binarize top-k
                    num_edges = data.edge_index.size(1)
                    k = max(1, int(pct * num_edges))
                    topk_idx = torch.topk(em.detach().cpu(), k).indices.to(DEVICE)
                    bin_mask = torch.zeros(num_edges, dtype=torch.bool, device=DEVICE)
                    bin_mask[topk_idx] = True
                    
                    fp, fm, sp = calculate_metrics(model, data.x, data.edge_index, data.batch, bin_mask, pred)
                    results.append([model_name, name, reg_strength, fp, fm, sp])
                    count += 1
                except Exception as e:
                    print(f"Error on graph {i} with {name}: {e}")
            
            print(f"{name}: Evaluated {count} graphs")
    
    return pd.DataFrame(results, columns=['Model', 'Explainer', 'RegStrength', 'Fidelity+', 'Fidelity-', 'Sparsity'])

# Plot
def plot_results(df, out_path="simple_results.png"):
    df_melt = df.melt(id_vars=['Model', 'Explainer', 'RegStrength'], var_name='Metric', value_name='Score')
    sns.catplot(data=df_melt, x='Model', y='Score', hue='Explainer', col='Metric', kind='box', sharey=False)
    plt.savefig(out_path, dpi=200, bbox_inches='tight')
    print(f"Saved plot to: {out_path}")

if __name__ == "__main__":
    df = run_experiment()
    print("\nMean Metrics:")
    print(df.groupby(['Model', 'Explainer'])[['Fidelity+', 'Fidelity-', 'Sparsity']].mean())
    plot_results(df)